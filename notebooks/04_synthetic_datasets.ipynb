{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6951be9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db753c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from py5canvas import *\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d7cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of images to record\n",
    "n_samples = 10\n",
    "\n",
    "# bw or colour?\n",
    "bnw = False\n",
    "\n",
    "DATASET_DIR = pathlib.Path(f\"datasets/synthetic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9dc0e",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DS = DATASET_DIR / \"images\"\n",
    "\n",
    "C = create_canvas(512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810b8ad",
   "metadata": {},
   "source": [
    "### Image Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a296dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_equilateral_triangle(centre, size, rotation):\n",
    "    begin_shape()\n",
    "    for i in range(3):\n",
    "        angle = rotation + TWO_PI / 3 * i\n",
    "        x = centre[0] + size / 2 * cos(angle)\n",
    "        y = centre[1] + size / 2 * sin(angle)\n",
    "        vertex(x, y)\n",
    "    end_shape(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17126026",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: rectangles, 1: ellipses, 2: triangles\n",
    "n_classes = 3\n",
    "class_names = [\"rectangle\", \"ellipse\", \"triangle\"]\n",
    "\n",
    "for sample_class in range(n_classes):\n",
    "\n",
    "    print(f\"Generating samples for class {sample_class} ({class_names[sample_class]})\")\n",
    "\n",
    "    out_dir = IMG_DS / f\"{class_names[sample_class]}\"\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        background(255)\n",
    "\n",
    "        if bnw:\n",
    "            fill(random(255), random(255))\n",
    "        else:\n",
    "            fill(random(255), random(255), random(255), random(255))\n",
    "\n",
    "        rotation = random(0, 2 * PI)\n",
    "        third_width = C.width / 3\n",
    "        third_height = C.height / 3\n",
    "\n",
    "        # draw\n",
    "        if sample_class == 0:\n",
    "            rect_mode(CENTER)\n",
    "            translate(center)\n",
    "            rotate(rotation)\n",
    "            rect(\n",
    "                random(-third_width, third_width),\n",
    "                random(-third_height, third_height),\n",
    "                random(10, third_width),\n",
    "                random(10, third_height),\n",
    "            )\n",
    "        elif sample_class == 1:\n",
    "            translate(center)\n",
    "            rotate(rotation)\n",
    "            ellipse(\n",
    "                random(-third_width, third_width),\n",
    "                random(-third_height, third_height),\n",
    "                random(10, third_width),\n",
    "                random(10, third_height),\n",
    "            )\n",
    "        else:\n",
    "            centre = create_vector(\n",
    "                random(third_width, C.width - third_width),\n",
    "                random(third_height, C.height - third_height)\n",
    "            )\n",
    "            size = random(10, C.width / 2)\n",
    "            draw_equilateral_triangle(centre, size, rotation)\n",
    "\n",
    "        # save\n",
    "        fname = out_dir / f\"{sample_class}_{i:0{len(str(n_samples))}}.png\"\n",
    "        save_image(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27406471",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([  \n",
    "    # tv.transforms.Grayscale(num_output_channels=1),\n",
    "    # tv.transforms.Resize(size=(28,28), antialias=True),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)    \n",
    "])\n",
    "\n",
    "img_ds = tv.datasets.ImageFolder(\n",
    "    IMG_DS,\n",
    "    transform=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds.class_to_idx['ellipse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in img_ds:\n",
    "    img, cl = b\n",
    "    print(img.shape, cl, img_ds.classes[cl])\n",
    "    plt.imshow(torch.einsum(\"cwh -> whc\", img))\n",
    "    plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d984983",
   "metadata": {},
   "source": [
    "## Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f845537",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOUND_DS = DATASET_DIR / \"sounds\"\n",
    "\n",
    "SAMPLE_RATE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773a220",
   "metadata": {},
   "source": [
    "### Sound Generation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952eb1ca",
   "metadata": {},
   "source": [
    "#### Single pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98557e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 440 Hz A note at 8000 Hz sample rate for 1 second\n",
    "\n",
    "def single_pitch(\n",
    "    frequency,\n",
    "    duration=1.0, # seconds\n",
    "    sample_rate=8000,\n",
    "):\n",
    "    # Create time array\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    \n",
    "    # Generate sine wave\n",
    "    audio_samples = np.sin(2 * np.pi * frequency * t)\n",
    "    \n",
    "    return audio_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples = single_pitch(\n",
    "    frequency = 440,  # Hz (A note)\n",
    ")\n",
    "\n",
    "\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b36bb4",
   "metadata": {},
   "source": [
    "#### Single sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sweep(\n",
    "    f_start,\n",
    "    f_end,\n",
    "    duration=1.0, # seconds\n",
    "    sample_rate=8000,\n",
    "):\n",
    "\n",
    "    # Generate a linear frequency sweep from 440 Hz to 880 Hz (one octave up) over 1 second\n",
    "    # Create time array\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "\n",
    "    # For a linear frequency sweep, we need to integrate the frequency to get the phase\n",
    "    # Phase = 2π * ∫ frequency(t) dt = 2π * ∫ (f_start + (f_end - f_start) * t) dt\n",
    "    # Phase = 2π * (f_start * t + (f_end - f_start) * t² / 2)\n",
    "    phase = 2 * np.pi * (f_start * t + (f_end - f_start) * t**2 / 2)\n",
    "\n",
    "    # Generate sine wave with changing frequency\n",
    "    audio_samples = np.sin(phase)\n",
    "\n",
    "    return audio_samples    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascending\n",
    "audio_samples = single_sweep(\n",
    "    f_start = 440,  # Hz (A note)\n",
    "    f_end = 880,    # Hz (A note one octave up)\n",
    ")\n",
    "\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descending\n",
    "audio_samples = single_sweep(\n",
    "    f_start = 880,  # Hz (A note)\n",
    "    f_end = 440,    # Hz (A note one octave up)\n",
    ")\n",
    "\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_pitch = np.random.randint(500, 1300)\n",
    "down_pitch = up_pitch - np.random.randint(100, 300)            \n",
    "audio_samples = single_sweep(\n",
    "    up_pitch,\n",
    "    down_pitch\n",
    ")\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20e82a",
   "metadata": {},
   "source": [
    "#### Down Up Down (& vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_sweep(\n",
    "    f_start,\n",
    "    f_mid,\n",
    "    f_end,\n",
    "    duration=1, # seconds\n",
    "    sample_rate=8000\n",
    "):\n",
    "    # Create time array\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    \n",
    "    # Create piecewise linear frequency array\n",
    "    # First half: f_start → f_mid\n",
    "    # Second half: f_mid → f_end\n",
    "    midpoint = duration / 2\n",
    "    frequency = np.where(\n",
    "        t < midpoint,\n",
    "        f_start + (f_mid - f_start) * (t / midpoint),  # First half\n",
    "        f_mid + (f_end - f_mid) * ((t - midpoint) / midpoint)  # Second half\n",
    "    )\n",
    "    \n",
    "    # For a piecewise linear frequency sweep, we need to integrate the frequency to get the phase\n",
    "    # Phase = 2π * ∫ frequency(t) dt\n",
    "    phase = np.zeros_like(t)\n",
    "    midpoint_idx = len(t) // 2\n",
    "    \n",
    "    # First half\n",
    "    t_first = t[:midpoint_idx]\n",
    "    phase[:midpoint_idx] = 2 * np.pi * (f_start * t_first + (f_mid - f_start) * t_first**2 / (2 * midpoint))\n",
    "    \n",
    "    # Second half: continue from where first half ended\n",
    "    t_second = t[midpoint_idx:] - midpoint\n",
    "    phase_midpoint = phase[midpoint_idx - 1]  # Phase at the midpoint\n",
    "    phase[midpoint_idx:] = phase_midpoint + 2 * np.pi * (f_mid * t_second + (f_end - f_mid) * t_second**2 / (2 * midpoint))\n",
    "    \n",
    "    # Generate sine wave with changing frequency\n",
    "    audio_samples = np.sin(phase)\n",
    "    \n",
    "    return audio_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples = piecewise_sweep(\n",
    "    f_start = 440,  # Hz (A note)\n",
    "    f_mid = 880,    # Hz (A note one octave up)\n",
    "    f_end = 440,    # Hz (back to A note)\n",
    ")\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42605859",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples = piecewise_sweep(\n",
    "    f_start = 880,  # Hz (A note one octave up)\n",
    "    f_mid = 440,    # Hz (A note)\n",
    "    f_end = 880,    # Hz (back to one octave up)\n",
    ")\n",
    "ipd.Audio(audio_samples, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b233ae",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8379b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "# 1: fixed pitch; 2: up sweep; 3: down sweep; 4: down up down; 5: up down up\n",
    "n_classes = 5\n",
    "class_names = [\"fixed_pitch\", \"up_sweep\", \"down_sweep\", \"down_up_down\", \"up_down_up\"]\n",
    "\n",
    "for sample_class in range(n_classes):\n",
    "\n",
    "    msg = f\"Generating samples for class {sample_class} ({class_names[sample_class]})\"\n",
    "\n",
    "    out_dir = SOUND_DS / f\"{class_names[sample_class]}\"\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        if sample_class == 0:\n",
    "            audio_samples = single_pitch(\n",
    "                np.random.randint(200, 1200)\n",
    "            )\n",
    "        elif sample_class == 1:\n",
    "            # up\n",
    "            down_pitch = np.random.randint(200, 1000)\n",
    "            up_pitch = down_pitch + np.random.randint(100, 300)\n",
    "            audio_samples = single_sweep(\n",
    "                down_pitch,\n",
    "                up_pitch\n",
    "            )\n",
    "        elif sample_class == 2:\n",
    "            # down\n",
    "            up_pitch = np.random.randint(500, 1300)\n",
    "            down_pitch = up_pitch - np.random.randint(100, 300)            \n",
    "            audio_samples = single_sweep(\n",
    "                up_pitch,\n",
    "                down_pitch\n",
    "            )\n",
    "        elif sample_class == 3:\n",
    "            # down up down\n",
    "            down_pitch = np.random.randint(200, 1000)\n",
    "            up_pitch = down_pitch + np.random.randint(100, 300)            \n",
    "            audio_samples = piecewise_sweep(\n",
    "                down_pitch,\n",
    "                up_pitch,\n",
    "                down_pitch,\n",
    "            )            \n",
    "        elif sample_class == 4:\n",
    "            # up down up\n",
    "            up_pitch = np.random.randint(500, 1300)\n",
    "            down_pitch = up_pitch - np.random.randint(100, 300)              \n",
    "            audio_samples = piecewise_sweep(\n",
    "                up_pitch,\n",
    "                down_pitch,\n",
    "                up_pitch,\n",
    "            )           \n",
    "\n",
    "        # Convert numpy array to torch tensor\n",
    "        audio_tensor = torch.from_numpy(audio_samples).float()\n",
    "\n",
    "        # Save as WAV file\n",
    "        # torchaudio.save expects shape (channels, samples) or (samples,)\n",
    "        # For mono audio, we need to add a channel dimension: (1, samples)\n",
    "        audio_tensor = audio_tensor.unsqueeze(0)  # Add channel dimension: (1, 8000)\n",
    "\n",
    "        # save\n",
    "        fname = out_dir / f\"{sample_class}_{i:0{len(str(n_samples))}}.wav\"\n",
    "        ipd.clear_output(wait=True)\n",
    "        print(f\"{msg} | {fname}\")\n",
    "\n",
    "        output_path = out_dir /  \"descending_sweep.wav\"\n",
    "        torchaudio.save(fname, audio_tensor, SAMPLE_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e70a52",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad28e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_EXTENSIONS = [\".wav\"]\n",
    "\n",
    "# Source: https://github.com/bellchenx/AudioFolder-Dataloader-PyTorch/blob/master/dataloader.py\n",
    "\n",
    "def is_audio_file(filename):\n",
    "    filename_lower = filename.lower()\n",
    "    return any(filename_lower.endswith(ext) for ext in AUDIO_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dirname, class_to_idx):\n",
    "    audio = []\n",
    "    dirname = os.path.expanduser(dirname)\n",
    "    for label in sorted(os.listdir(dirname)):\n",
    "        d = os.path.join(dirname, label)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_audio_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_to_idx[label])\n",
    "                    audio.append(item)\n",
    "    return audio\n",
    "\n",
    "def find_classes(dirname):\n",
    "    classes = [d for d in os.listdir(dirname) if os.path.isdir(os.path.join(dirname, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "class AudioFolder(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        transform=None\n",
    "    ):\n",
    "        \n",
    "        classes, class_to_idx = find_classes(root)\n",
    "        audios = make_dataset(root, class_to_idx)\n",
    "        if len(audios) == 0:\n",
    "            raise(RuntimeError(\"Found 0 audios in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported audio extensions are: \" + \",\".join(AUDIO_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.audios = audios\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, label = self.audios[index]\n",
    "        audio, _ = torchaudio.load(path)\n",
    "        if self.transform is not None:\n",
    "            audio = self.transform(audio)\n",
    "        return audio, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0540bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ds = AudioFolder(SOUND_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af86006",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in audio_ds:\n",
    "    sample, cl = b\n",
    "    print(sample.shape, cl, audio_ds.idx_to_class[cl])\n",
    "    ipd.display(ipd.Audio(sample, rate=SAMPLE_RATE))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc7a95",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f341d",
   "metadata": {},
   "source": [
    "- Create nice(r) classes samples!\n",
    "- Add more noise at various levels of the generation process!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
